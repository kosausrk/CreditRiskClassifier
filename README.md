# **production ready, v1.01**

# Credit Risk Classifier  AI-Powered Loan Default Predictor

This project simulates a lightweight credit risk engine similar to what fintechs or prop trading firms like **Akuna Capital** might use for real-time underwriting, risk flagging, or capital allocation decisions.


A machine learning application that predicts the probability of loan default based on customer financial data. Designed for financial institutions like JPMorgan and Capital One to automate risk underwriting with interpretable insights.


Additionally, this project is a practical demonstration of machine learning applied to **financial decision support**. It helps simulate how institutions might assess loan risk by analyzing borrower-related features (like income, credit score, loan amount, etc.) to estimate the **likelihood of repayment challenges** â€” similar to tools used in responsible lending and credit assessment.

---

**Use Case**:  
> "Can we estimate, with transparency, how various financial factors influence lending decisions?"

This tool enables that â€” combining predictive insights with model explainability (via SHAP).  
It transforms complex CSV data into clear, interpretable visual guidance.

---

## ğŸ§  In Simple Terms

Think of this app like a **virtual assistant for financial analysis**:

- You input details like income, credit score, and loan amount (or upload a CSV)
- The ML model estimates the **relative risk** based on patterns from past data
- It uses XGBoost â€” a fast, interpretable machine learning model
- It also shows **why** the model made its decision using SHAP (e.g., â€œLow income and high loan size contributed to higher riskâ€)

**Analogy**:  
Itâ€™s like a **financial calculator with explainable reasoning** â€” helping analysts or students understand risk patterns, not pass judgment.

> âš ï¸ Note: This tool is for educational purposes and should **not** be used to make real-world lending decisions.
---

## Who This Is For

- **Banks & Fintechs**: Streamline risk scoring for consumer lending
- **Analysts**: Get transparency into why a loan is flagged as risky
- **Students/Builders**: Learn end-to-end ML pipeline + UI + explainability


## Image Gallery â€“ Model Insights & UI

Visual examples from the pipeline and Streamlit app. Each graphic helps explain how this tool works for both technical and non-technical audiences.

| ğŸ” What You See | ğŸ§  What It Shows |
|----------------|------------------|
| ![Confusion Matrix](images/confusion-matrix.png) | A performance summary: how well the model predicts defaults vs non-defaults. Great for model audit snapshots. |
| ![Precision-Recall Curve](images/precision-recall-curve.png) | Shows the tradeoff between precision and recall â€” especially helpful in imbalanced datasets like credit risk. |
| ![SHAP Feature Values](images/SHAP_value.png) | A global SHAP beeswarm plot that highlights which features push the model toward predicting risk. Think of this as â€œwhat the model pays attention toâ€. |
| ![Streamlit App Screenshot](images/streamlit_web.png) | A look at the real-time scoring UI, where users input data manually or upload a CSV to get loan risk predictions. |




# DOCS (in progress)
current scores (as of 7/3/25)
ROC AUC: 0.7591999315970401
              precision    recall  f1-score   support

           0       0.89      1.00      0.94     45139
           1       0.63      0.06      0.11      5931

    accuracy                           0.89     51070
   macro avg       0.76      0.53      0.52     51070
weighted avg       0.86      0.89      0.84     51070

Metric	Meaning
Accuracy	89% of total predictions were correct
Macro Avg	Unweighted average over both classes (fairer)
Weighted Avg	Average, weighted by class size (skewed by class 0)


---

## How to Use the Streamlit Interface

### â¤ Manual Mode
1. Run the app:
   ```bash
   streamlit run app/streamlit.py


---

## Features

- **Exploratory Data Analysis** (EDA) â€“ Understand correlations, outliers, and data health
- **Modeling** â€“ Logistic Regression, Random Forest, and XGBoost with Grid Search
- **Explainability** â€“ SHAP visualizations to satisfy regulatory transparency
- **Streamlit App** â€“ Real-time prediction interface with interpretability toggle

---

## Tech Stack

- Python Â· Pandas Â· Scikit-learn Â· XGBoost  
- Streamlit (UI) Â· SHAP (model explanations)  
- Matplotlib & Seaborn (visualization)

## Text UML/ Pipeline
```
1. Data Understanding
   â”œâ”€ Gather example datasets (e.g., LendingClub, Kaggle credit datasets)
   â”œâ”€ Explore feature types: income, credit score, loan amount, etc.
   â””â”€ Identify target variable (loan default = 0/1)

2. Exploratory Data Analysis (EDA)
   â”œâ”€ Correlation analysis, outlier detection
   â”œâ”€ Missing value imputation
   â””â”€ Visualizations: boxplots, heatmaps, histograms

3. Data Preprocessing
   â”œâ”€ Encoding categorical variables
   â”œâ”€ Normalization/Standardization
   â””â”€ Train-test split (stratified)

4. Model Development
   â”œâ”€ Baseline: Logistic Regression
   â”œâ”€ Advanced: Random Forest, XGBoost
   â”œâ”€ Cross-validation (e.g., StratifiedKFold)
   â””â”€ Hyperparameter tuning (GridSearchCV / Optuna)

5. Model Evaluation
   â”œâ”€ Metrics: ROC AUC, F1, Precision-Recall
   â””â”€ Confusion matrix visualizations

6. Interpretability
   â”œâ”€ Feature importance (XGBoost built-in)
   â””â”€ SHAP plots (force, beeswarm, summary)

7. Streamlit App
   â”œâ”€ Input form for user financial data
   â”œâ”€ Risk prediction output
   â””â”€ Display SHAP explanations

8. Deployment (Optional)
   â””â”€ Streamlit Cloud / Dockerize for local hosting
```

## CreditRiskClassifier File Structure 

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â””â”€â”€ 02_model_dev.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ shap_analysis.py
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ xgb_credit_model.pkl
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---



## How to Run

1. **Install Dependencies**

   ```bash
   pip install -r requirements.txt


## DEV WORKFLOW 

1. Activate venv
source venv/bin/activate

2. If retraining is needed
python run_pipeline.py

3. Launch UI
streamlit run app/streamlit.py
