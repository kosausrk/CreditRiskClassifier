# **production ready, v1.01**

# Credit Risk Classifier  AI-Powered Loan Default Predictor

This project simulates a lightweight credit risk engine similar to what fintechs or prop trading firms like **Akuna Capital** might use for real-time underwriting, risk flagging, or capital allocation decisions.


A machine learning application that predicts the probability of loan default based on customer financial data. Designed for financial institutions like JPMorgan and Capital One to automate risk underwriting with interpretable insights.


Additionally,  practical ML application that helps banks and lenders automatically assess loan risk. It uses customer financial data (income, credit score, loan amount, etc.) to estimate the **probability of default** â€” like how JPMorgan or Capital One might screen applicants during underwriting.



**Use Case**:  
> "Can we tell, in seconds, whether this person is a low-risk borrower?"

This tool answers that â€” with both predictive power and explainability (via SHAP).  
It turns messy CSVs into clear visual decisions.

---

## (in Simple Terms)

Think of this app like a **digital loan officer assistant**:

- You type in someone's income, credit score, etc. (or upload a CSV)
- The trained ML model predicts: _What's the chance they won't pay us back?_
- It uses XGBoost â€” a model trained on real-world patterns
- It explains the reasoning visually using SHAP (like saying: â€œThis personâ€™s low credit score hurt their chancesâ€)

**Analogy**:  
Itâ€™s like TurboTax â€” but for risk analysis instead of taxes.

---

## Who This Is For

- **Banks & Fintechs**: Streamline risk scoring for consumer lending
- **Analysts**: Get transparency into why a loan is flagged as risky
- **Students/Builders**: Learn end-to-end ML pipeline + UI + explainability


## Image Gallery â€“ Model Insights & UI

Visual examples from the pipeline and Streamlit app. Each graphic helps explain how this tool works for both technical and non-technical audiences.

| ğŸ” What You See | ğŸ§  What It Shows |
|----------------|------------------|
| ![Confusion Matrix](images/confusion-matrix.png) | A performance summary: how well the model predicts defaults vs non-defaults. Great for model audit snapshots. |
| ![Precision-Recall Curve](images/precision-recall-curve.png) | Shows the tradeoff between precision and recall â€” especially helpful in imbalanced datasets like credit risk. |
| ![SHAP Feature Values](images/SHAP_value.png) | A global SHAP beeswarm plot that highlights which features push the model toward predicting risk. Think of this as â€œwhat the model pays attention toâ€. |
| ![Streamlit App Screenshot](images/streamlit_web.png) | A look at the real-time scoring UI, where users input data manually or upload a CSV to get loan risk predictions. |




# DOCS (in progress)

---

## How to Use the Streamlit Interface

### â¤ Manual Mode
1. Run the app:
   ```bash
   streamlit run app/streamlit.py


---

## Features

- **Exploratory Data Analysis** (EDA) â€“ Understand correlations, outliers, and data health
- **Modeling** â€“ Logistic Regression, Random Forest, and XGBoost with Grid Search
- **Explainability** â€“ SHAP visualizations to satisfy regulatory transparency
- **Streamlit App** â€“ Real-time prediction interface with interpretability toggle

---

## Tech Stack

- Python Â· Pandas Â· Scikit-learn Â· XGBoost  
- Streamlit (UI) Â· SHAP (model explanations)  
- Matplotlib & Seaborn (visualization)

## Text UML/ Pipeline
```
1. Data Understanding
   â”œâ”€ Gather example datasets (e.g., LendingClub, Kaggle credit datasets)
   â”œâ”€ Explore feature types: income, credit score, loan amount, etc.
   â””â”€ Identify target variable (loan default = 0/1)

2. Exploratory Data Analysis (EDA)
   â”œâ”€ Correlation analysis, outlier detection
   â”œâ”€ Missing value imputation
   â””â”€ Visualizations: boxplots, heatmaps, histograms

3. Data Preprocessing
   â”œâ”€ Encoding categorical variables
   â”œâ”€ Normalization/Standardization
   â””â”€ Train-test split (stratified)

4. Model Development
   â”œâ”€ Baseline: Logistic Regression
   â”œâ”€ Advanced: Random Forest, XGBoost
   â”œâ”€ Cross-validation (e.g., StratifiedKFold)
   â””â”€ Hyperparameter tuning (GridSearchCV / Optuna)

5. Model Evaluation
   â”œâ”€ Metrics: ROC AUC, F1, Precision-Recall
   â””â”€ Confusion matrix visualizations

6. Interpretability
   â”œâ”€ Feature importance (XGBoost built-in)
   â””â”€ SHAP plots (force, beeswarm, summary)

7. Streamlit App
   â”œâ”€ Input form for user financial data
   â”œâ”€ Risk prediction output
   â””â”€ Display SHAP explanations

8. Deployment (Optional)
   â””â”€ Streamlit Cloud / Dockerize for local hosting
```

## CreditRiskClassifier File Structure 

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â””â”€â”€ 02_model_dev.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ shap_analysis.py
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ xgb_credit_model.pkl
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---



## How to Run

1. **Install Dependencies**

   ```bash
   pip install -r requirements.txt


## DEV WORKFLOW 

1. Activate venv
source venv/bin/activate

2. If retraining is needed
python run_pipeline.py

3. Launch UI
streamlit run app/streamlit.py
